@article{b954efe5e46b8952f5a8daf42e7e535119b5408b,
title = {Development and Validation of a Deep Learning System for Diabetic Retinopathy and Related Eye Diseases Using Retinal Images From Multiethnic Populations With Diabetes},
year = {2017},
url = {https://www.semanticscholar.org/paper/b954efe5e46b8952f5a8daf42e7e535119b5408b},
abstract = {Importance A deep learning system (DLS) is a machine learning technology with potential for screening diabetic retinopathy and related eye diseases. Objective To evaluate the performance of a DLS in detecting referable diabetic retinopathy, vision-threatening diabetic retinopathy, possible glaucoma, and age-related macular degeneration (AMD) in community and clinic-based multiethnic populations with diabetes. Design, Setting, and Participants Diagnostic performance of a DLS for diabetic retinopathy and related eye diseases was evaluated using 494 661 retinal images. A DLS was trained for detecting diabetic retinopathy (using 76 370 images), possible glaucoma (125 189 images), and AMD (72 610 images), and performance of DLS was evaluated for detecting diabetic retinopathy (using 112 648 images), possible glaucoma (71 896 images), and AMD (35 948 images). Training of the DLS was completed in May 2016, and validation of the DLS was completed in May 2017 for detection of referable diabetic retinopathy (moderate nonproliferative diabetic retinopathy or worse) and vision-threatening diabetic retinopathy (severe nonproliferative diabetic retinopathy or worse) using a primary validation data set in the Singapore National Diabetic Retinopathy Screening Program and 10 multiethnic cohorts with diabetes. Exposures Use of a deep learning system. Main Outcomes and Measures Area under the receiver operating characteristic curve (AUC) and sensitivity and specificity of the DLS with professional graders (retinal specialists, general ophthalmologists, trained graders, or optometrists) as the reference standard. Results In the primary validation dataset (n = 14 880 patients; 71 896 images; mean [SD] age, 60.2 [2.2] years; 54.6% men), the prevalence of referable diabetic retinopathy was 3.0%; vision-threatening diabetic retinopathy, 0.6%; possible glaucoma, 0.1%; and AMD, 2.5%. The AUC of the DLS for referable diabetic retinopathy was 0.936 (95% CI, 0.925-0.943), sensitivity was 90.5% (95% CI, 87.3%-93.0%), and specificity was 91.6% (95% CI, 91.0%-92.2%). For vision-threatening diabetic retinopathy, AUC was 0.958 (95% CI, 0.956-0.961), sensitivity was 100% (95% CI, 94.1%-100.0%), and specificity was 91.1% (95% CI, 90.7%-91.4%). For possible glaucoma, AUC was 0.942 (95% CI, 0.929-0.954), sensitivity was 96.4% (95% CI, 81.7%-99.9%), and specificity was 87.2% (95% CI, 86.8%-87.5%). For AMD, AUC was 0.931 (95% CI, 0.928-0.935), sensitivity was 93.2% (95% CI, 91.1%-99.8%), and specificity was 88.7% (95% CI, 88.3%-89.0%). For referable diabetic retinopathy in the 10 additional datasets, AUC range was 0.889 to 0.983 (n = 40 752 images). Conclusions and Relevance In this evaluation of retinal images from multiethnic cohorts of patients with diabetes, the DLS had high sensitivity and specificity for identifying diabetic retinopathy and related eye diseases. Further research is necessary to evaluate the applicability of the DLS in health care settings and the utility of the DLS to improve vision outcomes.},
author = {D. Ting and C. Cheung and Gilbert Lim and G. Tan and N. Quang and A. Gan and Haslina Hamzah and R. García-Franco and Ian Yew San Yeo and S. Lee and E. Wong and C. Sabanayagam and M. Baskaran and Farah Ibrahim and N. Tan and E. Finkelstein and E. Lamoureux and I. Wong and N. Bressler and S. Sivaprasad and R. Varma and J. Jonas and M. He and Ching-Yu Cheng and G. Cheung and T. Aung and W. Hsu and M. Lee and T. Wong},
journal = {JAMA},
volume = {318},
pages = {2211–2223},
doi = {10.1001/jama.2017.18152},
pmid = {29234807},
}

@article{b2d952fbd6951cbed68ea13003a045300970731a,
title = {Clinically applicable deep learning for diagnosis and referral in retinal disease},
year = {2018},
url = {https://www.semanticscholar.org/paper/b2d952fbd6951cbed68ea13003a045300970731a},
abstract = {S2 TL;DR: This work applies a novel deep learning architecture to a clinically heterogeneous set of three-dimensional optical coherence tomography scans from patients referred to a major eye hospital and demonstrates performance in making a referral recommendation that reaches or exceeds that of experts on a range of sight-threatening retinal diseases.},
author = {Jeffrey De Fauw and J. Ledsam and Bernardino Romera-Paredes and Stanislav Nikolov and Nenad Tomašev and Sam Blackwell and Harry Askham and Xavier Glorot and Brendan O'Donoghue and D. Visentin and George Van Den Driessche and Balaji Lakshminarayanan and Clemens Meyer and Faith Mackinder and Simon Bouton and K. Ayoub and Reena Chopra and Dominic King and A. Karthikesalingam and Cían O. Hughes and R. Raine and J. Hughes and D. Sim and C. Egan and A. Tufail and Hugh Montgomery and D. Hassabis and G. Rees and T. Back and P. Khaw and Mustafa Suleyman and Julien Cornebise and P. Keane and O. Ronneberger},
journal = {Nature Medicine},
volume = {24},
pages = {1342 - 1350},
doi = {10.1038/s41591-018-0107-6},
pmid = {30104768},
}

@article{f5d7bc22f54b98db66ebf9818a77b3a8a402e436,
title = {Automated Diagnosis of Plus Disease in Retinopathy of Prematurity Using Deep Convolutional Neural Networks},
year = {2018},
url = {https://www.semanticscholar.org/paper/f5d7bc22f54b98db66ebf9818a77b3a8a402e436},
abstract = {Importance Retinopathy of prematurity (ROP) is a leading cause of childhood blindness worldwide. The decision to treat is primarily based on the presence of plus disease, defined as dilation and tortuosity of retinal vessels. However, clinical diagnosis of plus disease is highly subjective and variable. Objective To implement and validate an algorithm based on deep learning to automatically diagnose plus disease from retinal photographs. Design, Setting, and Participants A deep convolutional neural network was trained using a data set of 5511 retinal photographs. Each image was previously assigned a reference standard diagnosis (RSD) based on consensus of image grading by 3 experts and clinical diagnosis by 1 expert (ie, normal, pre–plus disease, or plus disease). The algorithm was evaluated by 5-fold cross-validation and tested on an independent set of 100 images. Images were collected from 8 academic institutions participating in the Imaging and Informatics in ROP (i-ROP) cohort study. The deep learning algorithm was tested against 8 ROP experts, each of whom had more than 10 years of clinical experience and more than 5 peer-reviewed publications about ROP. Data were collected from July 2011 to December 2016. Data were analyzed from December 2016 to September 2017. Exposures A deep learning algorithm trained on retinal photographs. Main Outcomes and Measures Receiver operating characteristic analysis was performed to evaluate performance of the algorithm against the RSD. Quadratic-weighted &kgr; coefficients were calculated for ternary classification (ie, normal, pre–plus disease, and plus disease) to measure agreement with the RSD and 8 independent experts. Results Of the 5511 included retinal photographs, 4535 (82.3%) were graded as normal, 805 (14.6%) as pre–plus disease, and 172 (3.1%) as plus disease, based on the RSD. Mean (SD) area under the receiver operating characteristic curve statistics were 0.94 (0.01) for the diagnosis of normal (vs pre–plus disease or plus disease) and 0.98 (0.01) for the diagnosis of plus disease (vs normal or pre–plus disease). For diagnosis of plus disease in an independent test set of 100 retinal images, the algorithm achieved a sensitivity of 93% with 94% specificity. For detection of pre–plus disease or worse, the sensitivity and specificity were 100% and 94%, respectively. On the same test set, the algorithm achieved a quadratic-weighted &kgr; coefficient of 0.92 compared with the RSD, outperforming 6 of 8 ROP experts. Conclusions and Relevance This fully automated algorithm diagnosed plus disease in ROP with comparable or better accuracy than human experts. This has potential applications in disease detection, monitoring, and prognosis in infants at risk of ROP.},
author = {James M. Brown and J. Campbell and Andrew L Beers and Ken Chang and S. Ostmo and R. Chan and Jennifer G. Dy and Deniz Erdoğmuş and Stratis Ioannidis and Jayashree Kalpathy-Cramer and M. Chiang},
journal = {JAMA Ophthalmology},
volume = {136},
pages = {803–810},
doi = {10.1001/jamaophthalmol.2018.1934},
pmid = {29801159},
}

@article{2d9597a69e58b27ffb8531abb885da62432666d3,
title = {Artificial intelligence and deep learning in ophthalmology},
year = {2018},
url = {https://www.semanticscholar.org/paper/2d9597a69e58b27ffb8531abb885da62432666d3},
abstract = {Artificial intelligence (AI) based on deep learning (DL) has sparked tremendous global interest in recent years. DL has been widely adopted in image recognition, speech recognition and natural language processing, but is only beginning to impact on healthcare. In ophthalmology, DL has been applied to fundus photographs, optical coherence tomography and visual fields, achieving robust classification performance in the detection of diabetic retinopathy and retinopathy of prematurity, the glaucoma-like disc, macular oedema and age-related macular degeneration. DL in ocular imaging may be used in conjunction with telemedicine as a possible solution to screen, diagnose and monitor major eye diseases for patients in primary care and community settings. Nonetheless, there are also potential challenges with DL application in ophthalmology, including clinical and technical challenges, explainability of the algorithm results, medicolegal issues, and physician and patient acceptance of the AI ‘black-box’ algorithms. DL could potentially revolutionise how ophthalmology is practised in the future. This review provides a summary of the state-of-the-art DL systems described for ophthalmic applications, potential challenges in clinical deployment and the path forward.},
author = {D. Ting and L. Pasquale and L. Peng and J. P. Campbell and Aaron Y. Lee and R. Raman and G. Tan and L. Schmetterer and P. Keane and T. Wong},
journal = {The British Journal of Ophthalmology},
volume = {103},
pages = {167 - 175},
doi = {10.1136/bjophthalmol-2018-313173},
pmid = {30361278},
}

@article{6f06bca6a45c4213b48f572d5255a0a5500e674a,
title = {An Automated Grading System for Detection of Vision-Threatening Referable Diabetic Retinopathy on the Basis of Color Fundus Photographs},
year = {2018},
url = {https://www.semanticscholar.org/paper/6f06bca6a45c4213b48f572d5255a0a5500e674a},
abstract = {OBJECTIVE The goal of this study was to describe the development and validation of an artificial intelligence–based, deep learning algorithm (DLA) for the detection of referable diabetic retinopathy (DR). RESEARCH DESIGN AND METHODS A DLA using a convolutional neural network was developed for automated detection of vision-threatening referable DR (preproliferative DR or worse, diabetic macular edema, or both). The DLA was tested by using a set of 106,244 nonstereoscopic retinal images. A panel of ophthalmologists graded DR severity in retinal photographs included in the development and internal validation data sets (n = 71,043); a reference standard grading was assigned once three graders achieved consistent grading outcomes. For external validation, we tested our DLA using 35,201 images of 14,520 eyes (904 eyes with any DR; 401 eyes with vision-threatening referable DR) from population-based cohorts of Malays, Caucasian Australians, and Indigenous Australians. RESULTS Among the 71,043 retinal images in the training and validation data sets, 12,329 showed vision-threatening referable DR. In the internal validation data set, the area under the curve (AUC), sensitivity, and specificity of the DLA for vision-threatening referable DR were 0.989, 97.0%, and 91.4%, respectively. Testing against the independent, multiethnic data set achieved an AUC, sensitivity, and specificity of 0.955, 92.5%, and 98.5%, respectively. Among false-positive cases, 85.6% were due to a misclassification of mild or moderate DR. Undetected intraretinal microvascular abnormalities accounted for 77.3% of all false-negative cases. CONCLUSIONS This artificial intelligence–based DLA can be used with high accuracy in the detection of vision-threatening referable DR in retinal images. This technology offers potential to increase the efficiency and accessibility of DR screening programs.},
author = {Zhixi Li and S. Keel and Chi Liu and Yifan He and W. Meng and J. Scheetz and Pei Ying Lee and J. Shaw and D. Ting and T. Wong and H. Taylor and Robert T. Chang and M. He},
journal = {Diabetes Care},
volume = {41},
pages = {2509 - 2516},
doi = {10.2337/dc18-0147},
pmid = {30275284},
}

@article{87839706e763eee156089f01798019aae368cccc,
title = {Pivotal trial of an autonomous AI-based diagnostic system for detection of diabetic retinopathy in primary care offices},
year = {2018},
url = {https://www.semanticscholar.org/paper/6baebfd292cb7b914b404afcc75a3956c360a741},
abstract = {S2 TL;DR: FDA authorized the system for use by health care providers to detect more than mild DR and diabetic macular edema, making it, the first FDA authorized autonomous AI diagnostic system in any field of medicine, with the potential to help prevent vision loss in thousands of people with diabetes annually.},
author = {M. Abràmoff and P. Lavin and M. Birch and Nilay Shah and J. Folk},
journal = {NPJ Digital Medicine},
volume = {1},
pages = {null},
doi = {10.1038/s41746-018-0040-6},
pmid = {31304320},
}

@article{5881fb094b08dfbc93bea2a226040877f4535792,
title = {Artificial Intelligence, Machine Learning and Deep Learning in Ophthalmology: Current Clinical Relevance},
year = {2019},
url = {https://www.semanticscholar.org/paper/5881fb094b08dfbc93bea2a226040877f4535792},
abstract = {With the advent of computer graphic processing units, improvement in mathematical models and availability of big data, artificial intelligence (AI) using machine learning (ML) and deep learning (DL) techniques have achieved robust performance for potential application across many industries, including social-media, the internet of things, the automotive industry and healthcare. DL systems provide capability in image, speech and motion recognition as well as in natural language processing. In medicine, most of the progress of AI, ML and DL systems has been demonstrated in image-centric specialties such as radiology, dermatology and pathology. There is increasing interest in AI in ophthalmology. New studies, including pre-registered prospective clinical trials, have shown DL systems are effective in detecting diabetic retinopathy (DR), glaucoma, age-related macular degeneration, retinopathy of prematurity, refractive error and in identifying cardiovascular risk factors and diseases, using image based data such as fundus photographs and optical coherence tomography. Additionally, the application of ML to Humphrey visual fields may be useful in detecting glaucoma progression. There are fewer studies that incorporate clinical data in AL algorithms and no prospective studies to demonstrate that AI algorithms can predict the development of eye disease. This article describes the current global eye disease burden, clinical unmet needs and selected common ophthalmic conditions of public health importance for which AI and DL systems may be applicable. Technical and clinical aspects to build a DL system to address those gaps, and the potential challenges for clinical adoption are discussed. AI, ML and DL likely will play a crucial role in clinical ophthalmology practice, with implications for screening, diagnosis and follow up of the major causes of vision impairment, in the setting of the ageing population globally. Introduction With the advent of graphic processing units (GPUs), advances in mathematical models, the availability of big datasets and low cost sensors, artificial intelligence (AI) using machine learning (ML) techniques initially and deep learning (DL) techniques subsequently, has sparked tremendous interest in many industries. These include application of AI in social-media, the internet of things, finance and banking, the automotive industry and healthcare. AI systems can be designed not only for image, speech and motion recognition, but also in natural language processing. In medicine, the most robust AI algorithms have been demonstrated in image-centric specialties, including radiology, dermatology, pathology and increasingly so in ophthalmology. For example, Lakhani et al demonstrated excellent performance in detecting pulmonary tuberculosis from chest radiographs, while Esteva et al was able to differentiate malignant melanoma from benign lesions on skin photographs. In ophthalmology, there have been two major areas in which AI and new DL systems have been applied. First, AI systems have been shown in new studies, including preregistered prospective clinical trials, to accurately detect diabetic retinopathy (DR), 13 glaucoma, age-related macular degeneration (AMD), retinopathy of prematurity (ROP), and refractive error, from digital fundus photographs. A range of cardiovascular risk factors have also been accurately predicted from fundus photographs. Second, several retinal conditions [e.g., neovascular AMD, earlier stages of AMD, and diabetic macular edema (DME)] has also be detected accurately using optical coherence tomography (OCT). There are relatively fewer AI studies using other data, such as studies which show good performance in detecting glaucoma progression from serial Humphrey visual fields (HVFs). However, there are fewer studies that incorporate clinical and imaging data in AL algorithms, and no prospective studies to demonstrate that AI algorithms can predict the development of eye diseases over time. Furthermore, the implementation and adoption of AI into routine clinical care remains extremely challenging. These remain significant goals of AI research in ophthalmology This article describes basic concepts of AI, ML and DL and how such systems might address some of the global burdens created by common eye conditions. Furthermore, the technical and clinical aspects of developing and validating an AI/DL system, potential challenges and future directions are also discussed in this article. Artificial Intelligence, Machine Learning and Deep Learning AI was conceptualized in 1956, after a workshop at Dartmouth College (Figure 1). In the workshop, many AI groups showed promising results in computer learning of checkers strategies, solving word problems in algebra and proving logical theorems. These tasks involved mostly pattern recognition and computational learning. All AI systems were designed to execute and maximise its chance of ‘winning’ within a constructed environment. The term ‘machine learning’ (ML) was subsequently coined by Arthur Samuel in 1959 and stated that “the computer should have the ability to learn using various statistical techniques, without being explicitly programmed”. Using ML, the algorithm can learn and make predictions based on the data that has been fed into the training phase, using either a supervised or unsupervised approach. ML has been widely adopted in applications such as computer vision and predictive analytics using complex mathematical models. In supervised learning, the computer is trained with labelled examples, also known as ground truth, whereas for unsupervised learning, no labelling is required for the algorithm to find its own structure in the input. The majority of AI application in biomedical research uses supervised learning. DL utilizes multiple processing layers to learn representation of data with multiple levels of abstraction. Although some forms of deep neural networks have already been investigated in the past, the advent of graphic processing units (GPU) with improved processing power, larger annotated datasets, and other factors, have recently boosted its diagnostic performance in many domains. Using learning approaches such as backpropagation, a ML or DL system is able to discover intricate structure in large data sets, then changing its internal parameters that are used to compute the representation in each layer from the previous one. These approaches permit the use of regional samples to allow the network to learn to detect biomarkers; furthermore these approaches use complete images, and associate the entire image with a diagnostic output, thereby eliminating the use of “hand-engineered” image features. Given the much improved performance, DL has been widely adopted in image recognition, speech recognition and natural language processing. General Approach in Building a Robust AI system This section explains some common terminologies, software framework, network architectures, datasets selection, assistive vs. autonomous AI system, consideration factors to ensure the robustness of these algorithms (Table 1). In order to build a robust DL system, it is important to have 2 main components – the ‘brain’ (technical networks – Convolutional Neural Network (CNN) and the ‘dictionary’ (the datasets). 1. What is a CNN? A CNN is a deep neural network consisting of a cascade of processing layers that resemble the biological processes of the animal visual cortex. It transforms the input volume into an output volume via a differentiable function. Inspired by Hubel and Weisel, each neuron in the visual cortex will respond to the stimulus that is specific to a region within an image, similar to how the brain neuron would respond to the visual stimuli, that will activate a particular region of the visual space, known as the receptive field. These receptive fields are tiled together to cover the entire visual field. Two classes of cells are found in this region – simple vs complex cells. The simple cells active when they detect edge-like patterns, while the more complex cells activate when they have a larger receptive field and are invariant to the position of the pattern. Broadly, the CNN can be divided into the input, hidden (also known as featureextraction layers) and output layers (Figure 2A). The hidden layers usually consist of convolutional, pooling, fully connected and normalization layers, and the number of hidden layers will differ for different CNNs. The input layer specifies the width, height and the number of channels (usually 3 channels – red, green and blue). The convolutional layer is the core building block of a CNN, transforming the input data by applying a set of filters (also known as kernels) that acts as the feature detectors. The filter will slide over the input image to produce a feature map (as the output). A CNN learns the values of these filters weights on its own during the training process, although the specific parameters such as number of filters, filter size, network architecture still need to be set prior to that. Additional operations called activations (for example ReLU or Rectified Linear Unit) are used after every convolution operation. For pooling, the aim is to reduce the dimensionality of each feature map and make it somewhat spatially invariant, and retain the most important information. Pooling can be divided into different types: maximum, average and minimum. In the case of maximum pooling, the largest element from the rectified feature map will be taken (Figure 2B). The output from the convolutional and pooling layers represent the high-level features of the input image. The purpose of the fully connected layer is to use these high-level features to classify the input image into various classes based on the training dataset. Following which, backpropagation is conducted to compute the network weights and uses the gradient descent to update all filters and parameter values to minimize the output error. T},
author = {D. Ting and L. Peng and A. Varadarajan and Pearse Keane FRCOphth and P. Burlina and M. Chiang and L. Schmetterer and L. Pasquale and N. Bressler and D. Webster and M. Abràmoff and T. Y. Wong},
}

@article{682c280f238874f2f1347226cd2b110714e654e3,
title = {Artificial intelligence using deep learning to screen for referable and vision-threatening diabetic retinopathy in Africa: a clinical validation study.},
year = {2019},
url = {https://www.semanticscholar.org/paper/682c280f238874f2f1347226cd2b110714e654e3},
abstract = {S2 TL;DR: The accuracy of an artificial intelligence (AI) model using deep learning in a population-based diabetic retinopathy screening programme in Zambia shows the potential application and adoption of such AI technology in an under-resourced African population to reduce the incidence of preventable blindness.},
author = {V. Bellemo and Z. Lim and Gilbert Lim and Q. Nguyen and Yuchen Xie and M. Yip and Haslina Hamzah and Jinyi Ho and X. Q. Lee and W. Hsu and M. Lee and Lillian Musonda and M. Chandran and G. Chipalo-Mutati and M. Muma and G. Tan and S. Sivaprasad and G. Menon and T. Wong and D. Ting},
journal = {The Lancet. Digital health},
volume = {1 1},
pages = {
          e35-e44
        },
doi = {10.1016/S2589-7500(19)30004-4},
pmid = {33323239},
}

@article{3695fe14596fb102ccf8bcc8ee6694d382b17da8,
title = {Artificial intelligence in retina},
year = {2018},
url = {https://www.semanticscholar.org/paper/3695fe14596fb102ccf8bcc8ee6694d382b17da8},
abstract = {null},
author = {U. Schmidt-Erfurth and A. Sadeghipour and Bianca S. Gerendas and S. Waldstein and H. Bogunović},
journal = {Progress in retinal and eye research},
volume = {67},
pages = {
          1-29
        },
doi = {10.1016/j.preteyeres.2018.07.004},
pmid = {30076935},
}

@article{ad577da37275a9a2605545a83a78cee34285bd51,
title = {Automatic Grading System for Diabetic Retinopathy Diagnosis Using Deep Learning Artificial Intelligence Software},
year = {2020},
url = {https://www.semanticscholar.org/paper/ad577da37275a9a2605545a83a78cee34285bd51},
abstract = {ABSTRACT Purposes: To describe the development and validation of an artificial intelligence–based, deep learning algorithm (DeepDR) for the detection of diabetic retinopathy (DR) in retinal fundus photographs. Methods: Five hundred fundus images, which had detailed labelling of DR lesions, were transmitted to be analysed, including localization of the optic disk and macular, vessel segmentation, detection of lesions, and grading of DR. The multi-level iterative method of convolutional neural network and the strategy of enhanced learning were used to improve the accuracy of the system (DeepDR) for grading DR. Three public data sets were used to further train the software. The final grading results were tested based on the fundus images provided by the hospitals. Results: For 6788 fundus images (both macular and disc centred) of two Hospital Eye Center, the detection of microaneurysm, haemorrhage and hard exudates had an accuracy of 99.7%, 98.4% and 98.1%, respectively. The current algorithm accuracy was 0.96. Another 20,000 fundus images from community screening were selected, and 7593 photos of poor quality were excluded according to quality standards. Accuracy for accurate staging of fundus photos: accuracy was 0.9179. The sensitivity, specificity and area under the curve (AUC) were 80.58%, 95.77% and 0.9327, respectively. Conclusions: This artificial intelligence–based DeepDR can be used with high accuracy for the detection of DR in retinal images. This technology offers the potential to increase the efficiency and accessibility of DR screening programs.},
author = {Xiangning Wang and Ling Dai and Shu-ting Li and Hongyu Kong and Bin Sheng and Qiang Wu},
journal = {Current Eye Research},
volume = {45},
pages = {1550 - 1555},
doi = {10.1080/02713683.2020.1764975},
pmid = {32410471},
}

@article{23ddb276e21da376b9049060b0f38a2f0b3481e8,
title = {Performance of a Deep-Learning Algorithm vs Manual Grading for Detecting Diabetic Retinopathy in India.},
year = {2019},
url = {https://www.semanticscholar.org/paper/23ddb276e21da376b9049060b0f38a2f0b3481e8},
abstract = {Importance
More than 60 million people in India have diabetes and are at risk for diabetic retinopathy (DR), a vision-threatening disease. Automated interpretation of retinal fundus photographs can help support and scale a robust screening program to detect DR.


Objective
To prospectively validate the performance of an automated DR system across 2 sites in India.


Design, Setting, and Participants
This prospective observational study was conducted at 2 eye care centers in India (Aravind Eye Hospital and Sankara Nethralaya) and included 3049 patients with diabetes. Data collection and patient enrollment took place between April 2016 and July 2016 at Aravind and May 2016 and April 2017 at Sankara Nethralaya. The model was trained and fixed in March 2016.


Interventions
Automated DR grading system compared with manual grading by 1 trained grader and 1 retina specialist from each site. Adjudication by a panel of 3 retinal specialists served as the reference standard in the cases of disagreement.


Main Outcomes and Measures
Sensitivity and specificity for moderate or worse DR or referable diabetic macula edema.


Results
Of 3049 patients, 1091 (35.8%) were women and the mean (SD) age for patients at Aravind and Sankara Nethralaya was 56.6 (9.0) years and 56.0 (10.0) years, respectively. For moderate or worse DR, the sensitivity and specificity for manual grading by individual nonadjudicator graders ranged from 73.4% to 89.8% and from 83.5% to 98.7%, respectively. The automated DR system's performance was equal to or exceeded manual grading, with an 88.9% sensitivity (95% CI, 85.8-91.5), 92.2% specificity (95% CI, 90.3-93.8), and an area under the curve of 0.963 on the data set from Aravind Eye Hospital and 92.1% sensitivity (95% CI, 90.1-93.8), 95.2% specificity (95% CI, 94.2-96.1), and an area under the curve of 0.980 on the data set from Sankara Nethralaya.


Conclusions and Relevance
This study shows that the automated DR system generalizes to this population of Indian patients in a prospective setting and demonstrates the feasibility of using an automated DR grading system to expand screening programs.},
author = {Varun Gulshan and Renu P Rajan and Kasumi Widner and Derek J. Wu and Peter Wubbels and Tyler Rhodes and Kira Whitehouse and Marc Coram and G. Corrado and K. Ramasamy and R. Raman and L. Peng and D. Webster},
journal = {JAMA ophthalmology},
volume = {null},
pages = {null},
doi = {10.1001/jamaophthalmol.2019.2004},
pmid = {31194246},
}

@article{6624ff407678a1f5103b5a95f719bfd7490cdbb7,
title = {Artificial Intelligence Screening for Diabetic Retinopathy: the Real-World Emerging Application},
year = {2019},
url = {https://www.semanticscholar.org/paper/6624ff407678a1f5103b5a95f719bfd7490cdbb7},
abstract = {S2 TL;DR: Given the rapid and impressive progress of artificial intelligence technologies, the implementation of deep learning systems into routinely practiced diabetic retinopathy screening could represent a cost-effective alternative to help reduce the incidence of preventable blindness around the world.},
author = {V. Bellemo and Gilbert Lim and T. Rim and G. Tan and C. Cheung and S. Sadda and M. He and A. Tufail and M. Lee and W. Hsu and D. Ting},
journal = {Current Diabetes Reports},
volume = {19},
pages = {null},
doi = {10.1007/s11892-019-1189-3},
pmid = {31367962},
}

@article{c0fe78d0cee0e9a776695de12f020c21b01728ea,
title = {Automated Grading of Age-Related Macular Degeneration From Color Fundus Images Using Deep Convolutional Neural Networks},
year = {2017},
url = {https://www.semanticscholar.org/paper/c0fe78d0cee0e9a776695de12f020c21b01728ea},
abstract = {Importance Age-related macular degeneration (AMD) affects millions of people throughout the world. The intermediate stage may go undetected, as it typically is asymptomatic. However, the preferred practice patterns for AMD recommend identifying individuals with this stage of the disease to educate how to monitor for the early detection of the choroidal neovascular stage before substantial vision loss has occurred and to consider dietary supplements that might reduce the risk of the disease progressing from the intermediate to the advanced stage. Identification, though, can be time-intensive and requires expertly trained individuals. Objective To develop methods for automatically detecting AMD from fundus images using a novel application of deep learning methods to the automated assessment of these images and to leverage artificial intelligence advances. Design, Setting, and Participants Deep convolutional neural networks that are explicitly trained for performing automated AMD grading were compared with an alternate deep learning method that used transfer learning and universal features and with a trained clinical grader. Age-related macular degeneration automated detection was applied to a 2-class classification problem in which the task was to distinguish the disease-free/early stages from the referable intermediate/advanced stages. Using several experiments that entailed different data partitioning, the performance of the machine algorithms and human graders in evaluating over 130 000 images that were deidentified with respect to age, sex, and race/ethnicity from 4613 patients against a gold standard included in the National Institutes of Health Age-related Eye Disease Study data set was evaluated. Main Outcomes and Measures Accuracy, receiver operating characteristics and area under the curve, and kappa score. Results The deep convolutional neural network method yielded accuracy (SD) that ranged between 88.4% (0.5%) and 91.6% (0.1%), the area under the receiver operating characteristic curve was between 0.94 and 0.96, and kappa coefficient (SD) between 0.764 (0.010) and 0.829 (0.003), which indicated a substantial agreement with the gold standard Age-related Eye Disease Study data set. Conclusions and Relevance Applying a deep learning–based automated assessment of AMD from fundus images can produce results that are similar to human performance levels. This study demonstrates that automated algorithms could play a role that is independent of expert human graders in the current management of AMD and could address the costs of screening or monitoring, access to health care, and the assessment of novel treatments that address the development or progression of AMD.},
author = {P. Burlina and Neil J. Joshi and M. Pekala and Katia D. Pacheco and D. E. Freund and N. Bressler},
journal = {JAMA Ophthalmology},
volume = {135},
pages = {1170–1176},
doi = {10.1001/jamaophthalmol.2017.3782},
pmid = {28973096},
}

@article{6e7fd39aedb82533f98a4568d7f305887a90a8aa,
title = {Deep learning in ophthalmology: The technical and clinical considerations},
year = {2019},
url = {https://www.semanticscholar.org/paper/6e7fd39aedb82533f98a4568d7f305887a90a8aa},
abstract = {S2 TL;DR: Global eye disease burden, unmet needs and common conditions of public health importance for which AI and DL systems may be applicable are described and the potential challenges for clinical adoption are discussed.},
author = {D. Ting and L. Peng and A. Varadarajan and P. Keane and P. Burlina and M. Chiang and L. Schmetterer and L. Pasquale and N. Bressler and D. Webster and M. Abràmoff and T. Wong},
journal = {Progress in Retinal and Eye Research},
volume = {72},
pages = {null},
doi = {10.1016/j.preteyeres.2019.04.003},
pmid = {31048019},
}

@article{a170c0e02b974b5fe99ff0746bf11a40ed4a6d2c,
title = {DeepSeeNet: A deep learning model for automated classification of patient-based age-related macular degeneration severity from color fundus photographs},
year = {2018},
url = {https://www.semanticscholar.org/paper/2c80a3a6fbc691e7e11266d9486b2814ebfe4db8},
abstract = {S2 TL;DR: By simulating the human grading process, DeepSeeNet demonstrated high accuracy with increased transparency in the automated assignment of individual patients to AMD risk categories based on the AREDS Simplified Severity Scale, highlighting the potential of deep learning to assist and enhance clinical decision-making in patients with AMD.},
author = {Yifan Peng and S. Dharssi and Qingyu Chen and T. Keenan and E. Agrón and W. Wong and E. Chew and Zhiyong Lu},
journal = {Ophthalmology},
volume = {126 4},
pages = {
          565-575
        },
doi = {10.1016/j.ophtha.2018.11.015},
pmid = {30471319},
arxivid = {1811.07492},
}

@article{6c0e900b627993b5a53e3eaf69f947f9fce9e75c,
title = {Deep learning in estimating prevalence and systemic risk factors for diabetic retinopathy: a multi-ethnic study},
year = {2019},
url = {https://www.semanticscholar.org/paper/6c0e900b627993b5a53e3eaf69f947f9fce9e75c},
abstract = {S2 TL;DR: The prevalence and systemic risk factors for DR in multi-ethnic population could be determined accurately using a DLS, in significantly less time than human assessors, and the potential use of AI for future epidemiology or clinical trials for DR grading in the global communities is highlighted.},
author = {D. Ting and C. Cheung and Q. Nguyen and C. Sabanayagam and Gilbert Lim and Z. Lim and G. Tan and Y. Soh and L. Schmetterer and Y. X. Wang and J. Jonas and R. Varma and M. Lee and W. Hsu and E. Lamoureux and Ching-Yu Cheng and T. Wong},
journal = {NPJ Digital Medicine},
volume = {2},
pages = {null},
doi = {10.1038/s41746-019-0097-x},
pmid = {31304371},
}

@article{614c0fb3b95438beb01ddde2274639ea1c38356d,
title = {Artificial Intelligence in Diabetic Eye Disease Screening},
year = {2019},
url = {https://www.semanticscholar.org/paper/614c0fb3b95438beb01ddde2274639ea1c38356d},
abstract = {Abstract: Systematic or national screening programs for diabetic retinopathy (DR) and diabetic macular edema (DME), using digital fundus photography and optical coherence tomography (OCT), are currently implemented at primary care level, aiming to provide timely referral for vision‐threatening DR and DME to ophthalmologists for timely treatment and vision loss prevention. However, interpretation of retinal images requires specialized knowledge and expertise in diabetic eye disease. Furthermore, current DR screening programs are capital‐ and labor‐intensive, which makes it difficult to rapidly scale up and expand diabetic eye screening to meet the needs of this growing global epidemic. Deep learning (DL), a new branch of machine learning technology under the broad term of artificial intelligence (AI), has made remarkable breakthrough in medical imaging in particular for pattern recognition and image classification. In ophthalmology, AI and DL technology has been developed from big image datasets in assessment of retinal photographs for detection and screening of DR as well as the segmentation and assessment of OCT images for diagnosis and screening of DME. This review aimed to summarize the current progress and the development of using AI and DL technology for diabetic eye disease screening as well as current challenges in the actual implementation of DL in screening programs, and translating DL research into direct clinical applications of screening in a community setting.},
author = {C. Cheung and Fangyao Tang and D. Ting and G. Tan and T. Wong},
journal = {Asia-Pacific Journal of Ophthalmology},
volume = {8},
pages = {158–164},
doi = {10.22608/APO.201976},
pmid = {31016915},
}

@article{f550c444c91174592a73df4476f9bc921af3c393,
title = {Efficacy of a Deep Learning System for Detecting Glaucomatous Optic Neuropathy Based on Color Fundus Photographs.},
year = {2018},
url = {https://www.semanticscholar.org/paper/f550c444c91174592a73df4476f9bc921af3c393},
abstract = {S2 TL;DR: A deep learning system can detect referable GON with high sensitivity and specificity and coexistence of high or pathologic myopia is the most common cause resulting in false-negative results.},
author = {Zhixi Li and Yifan He and S. Keel and W. Meng and R. Chang and M. He},
journal = {Ophthalmology},
volume = {125 8},
pages = {
          1199-1206
        },
doi = {10.1016/j.ophtha.2018.01.023},
pmid = {29506863},
}

@article{ed050b5c76d49d436da26cb787b18f73c25eec3a,
title = {The Value of Automated Diabetic Retinopathy Screening with the EyeArt System: A Study of More Than 100,000 Consecutive Encounters from People with Diabetes},
year = {2019},
url = {https://www.semanticscholar.org/paper/ed050b5c76d49d436da26cb787b18f73c25eec3a},
abstract = {Abstract Background: Current manual diabetic retinopathy (DR) screening using eye care experts cannot scale to screen the growing population of diabetes patients who are at risk for vision loss. EyeArt system is an automated, cloud-based artificial intelligence (AI) eye screening technology designed to easily detect referral-warranted DR immediately through automated analysis of patient's retinal images. Methods: This retrospective study assessed the diagnostic efficacy of the EyeArt system v2.0 analyzing 850,908 fundus images from 101,710 consecutive patient visits, collected from 404 primary care clinics. Presence or absence of referral-warranted DR (more than mild nonproliferative DR [NPDR]) was automatically detected by the EyeArt system for each patient encounter, and its performance was compared against a clinical reference standard of quality-assured grading by rigorously trained certified ophthalmologists and optometrists. Results: Of the 101,710 visits, 75.7% were nonreferable, 19.3% were referable to an eye care specialist, and in 5.0%, the DR level was unknown as per the clinical reference standard. EyeArt screening had 91.3% (95% confidence interval [CI]: 90.9–91.7) sensitivity and 91.1% (95% CI: 90.9–91.3) specificity. For 5446 encounters with potentially treatable DR (more than moderate NPDR and/or diabetic macular edema), the system provided a positive “refer” output to 5363 encounters achieving sensitivity of 98.5%. Conclusions: This study captures variations in real-world clinical practice and shows that an AI DR screening system can be safe and effective in the real world. This study demonstrates the value of this easy-to-use, automated tool for endocrinologists, diabetologists, and general practitioners to address the growing need for DR screening and monitoring.},
author = {Malavika Bhaskaranand and Chaithanya A. Ramachandra and Sandeep Bhat and Jorge A Cuadros and M. Nittala and S. Sadda and K. Solanki},
journal = {Diabetes Technology & Therapeutics},
volume = {21},
pages = {635 - 643},
doi = {10.1089/dia.2019.0164},
pmid = {31335200},
}

@article{6d66981faaf585948c7583c873e3695ee4d4a3ca,
title = {Use of Deep Learning for Detailed Severity Characterization and Estimation of 5-Year Risk Among Patients With Age-Related Macular Degeneration},
year = {2018},
url = {https://www.semanticscholar.org/paper/6d66981faaf585948c7583c873e3695ee4d4a3ca},
abstract = {Importance Although deep learning (DL) can identify the intermediate or advanced stages of age-related macular degeneration (AMD) as a binary yes or no, stratified gradings using the more granular Age-Related Eye Disease Study (AREDS) 9-step detailed severity scale for AMD provide more precise estimation of 5-year progression to advanced stages. The AREDS 9-step detailed scale’s complexity and implementation solely with highly trained fundus photograph graders potentially hampered its clinical use, warranting development and use of an alternate AREDS simple scale, which although valuable, has less predictive ability. Objective To describe DL techniques for the AREDS 9-step detailed severity scale for AMD to estimate 5-year risk probability with reasonable accuracy. Design, Setting, and Participants This study used data collected from November 13, 1992, to November 30, 2005, from 4613 study participants of the AREDS data set to develop deep convolutional neural networks that were trained to provide detailed automated AMD grading on several AMD severity classification scales, using a multiclass classification setting. Two AMD severity classification problems using criteria based on 4-step (AMD-1, AMD-2, AMD-3, and AMD-4 from classifications developed for AREDS eligibility criteria) and 9-step (from AREDS detailed severity scale) AMD severity scales were investigated. The performance of these algorithms was compared with a contemporary human grader and against a criterion standard (fundus photograph reading center graders) used at the time of AREDS enrollment and follow-up. Three methods for estimating 5-year risk were developed, including one based on DL regression. Data were analyzed from December 1, 2017, through April 15, 2018. Main Outcomes and Measures Weighted &kgr; scores and mean unsigned errors for estimating 5-year risk probability of progression to advanced AMD. Results This study used 67 401 color fundus images from the 4613 study participants. The weighted &kgr; scores were 0.77 for the 4-step and 0.74 for the 9-step AMD severity scales. The overall mean estimation error for the 5-year risk ranged from 3.5% to 5.3%. Conclusions and Relevance These findings suggest that DL AMD grading has, for the 4-step classification evaluation, performance comparable with that of humans and achieves promising results for providing AMD detailed severity grading (9-step classification), which normally requires highly trained graders, and for estimating 5-year risk of progression to advanced AMD. Use of DL has the potential to assist physicians in longitudinal care for individualized, detailed risk assessment as well as clinical studies of disease progression during treatment or as public screening or monitoring worldwide.},
author = {P. Burlina and Neil J. Joshi and Katia D. Pacheco and D. E. Freund and Jun Kong and N. Bressler},
journal = {JAMA Ophthalmology},
volume = {136},
pages = {1359–1366},
doi = {10.1001/jamaophthalmol.2018.4118},
pmid = {30242349},
}

@article{bfffbe425424c940fa408f0412e6b06e94c3515f,
title = {Evidence Based Prediction and Progression Monitoring on Retinal Images from Three Nations},
year = {2020},
url = {https://www.semanticscholar.org/paper/bfffbe425424c940fa408f0412e6b06e94c3515f},
abstract = {Purpose The aim of this work is to demonstrate how a retinal image analysis system, DAPHNE, supports the optimization of diabetic retinopathy (DR) screening programs for grading color fundus photography. Method Retinal image sets, graded by trained and certified human graders, were acquired from Saudi Arabia, China, and Kenya. Each image was subsequently analyzed by the DAPHNE automated software. The sensitivity, specificity, and positive and negative predictive values for the detection of referable DR or diabetic macular edema were evaluated, taking human grading or clinical assessment outcomes to be the gold standard. The automated software's ability to identify co-pathology and to correctly label DR lesions was also assessed. Results In all three datasets the agreement between the automated software and human grading was between 0.84 to 0.88. Sensitivity did not vary significantly between populations (94.28%–97.1%) with specificity ranging between 90.33% to 92.12%. There were excellent negative predictive values above 93% in all image sets. The software was able to monitor DR progression between baseline and follow-up images with the changes visualized. No cases of proliferative DR or DME were missed in the referable recommendations. Conclusions The DAPHNE automated software demonstrated its ability not only to grade images but also to reliably monitor and visualize progression. Therefore it has the potential to assist timely image analysis in patients with diabetes in varied populations and also help to discover subtle signs of sight-threatening disease onset. Translational Relevance This article takes research on machine vision and evaluates its readiness for clinical use.},
author = {L. A. Al Turk and Su Wang and Paul Krause and J. Wawrzynski and George Saleh and Hend M Alsawadi and Abdulrahman Zaid Alshamrani and T. Peto and A. Bastawrous and Jingren Li and H. Tang},
journal = {Translational Vision Science & Technology},
volume = {9},
pages = {null},
doi = {10.1167/tvst.9.2.44},
pmid = {32879754},
}

@article{a2b9917c2a88663b010aa26900636ff0056cecdb,
title = {Validation of automated screening for referable diabetic retinopathy with the IDx‐DR device in the Hoorn Diabetes Care System},
year = {2017},
url = {https://www.semanticscholar.org/paper/a2b9917c2a88663b010aa26900636ff0056cecdb},
abstract = {To increase the efficiency of retinal image grading, algorithms for automated grading have been developed, such as the IDx‐DR 2.0 device. We aimed to determine the ability of this device, incorporated in clinical work flow, to detect retinopathy in persons with type 2 diabetes.},
author = {A. A. van der Heijden and M. Abràmoff and F. Verbraak and M. van Hecke and A. Liem and G. Nijpels},
journal = {Acta Ophthalmologica},
volume = {96},
pages = {63 - 68},
doi = {10.1111/aos.13613},
pmid = {29178249},
}

@article{9e9ca70a45d4b2616bec1a9c03d3f9e048147d27,
title = {Grader variability and the importance of reference standards for evaluating machine learning models for diabetic retinopathy},
year = {2017},
url = {https://www.semanticscholar.org/paper/9e9ca70a45d4b2616bec1a9c03d3f9e048147d27},
abstract = {S2 TL;DR: Adjudication reduces the errors in DR grading by using a small number of adjudicated consensus grades as a tuning dataset and higher-resolution images as input, and to train an improved automated algorithm for DR grading.},
author = {Jonathan Krause and Varun Gulshan and E. Rahimy and Peter Karth and Kasumi Widner and G. Corrado and L. Peng and D. Webster},
journal = {Ophthalmology},
volume = {125 8},
pages = {
          1264-1272
        },
doi = {10.1016/j.ophtha.2018.01.034},
pmid = {29548646},
arxivid = {1710.01711},
}

@article{c819216d9896f6f5dbc8fc1c12b6e14a19a931f5,
title = {Replication study: Development and validation of deep learning algorithm for detection of diabetic retinopathy in retinal fundus photographs},
year = {2018},
url = {https://www.semanticscholar.org/paper/0206ebb3ce46cbb50eb1c593387d9ecabfd000ad},
abstract = {Replication studies are essential for validation of new methods, and are crucial to maintain the high standards of scientific publications, and to use the results in practice. We have attempted to replicate the main method in 'Development and validation of a deep learning algorithm for detection of diabetic retinopathy in retinal fundus photographs' published in JAMA 2016; 316(22). We re-implemented the method since the source code is not available, and we used publicly available data sets. The original study used non-public fundus images from EyePACS and three hospitals in India for training. We used a different EyePACS data set from Kaggle. The original study used the benchmark data set Messidor-2 to evaluate the algorithm's performance. We used the same data set. In the original study, ophthalmologists re-graded all images for diabetic retinopathy, macular edema, and image gradability. There was one diabetic retinopathy grade per image for our data sets, and we assessed image gradability ourselves. Hyper-parameter settings were not described in the original study. But some of these were later published. We were not able to replicate the original study. Our algorithm's area under the receiver operating curve (AUC) of 0.94 on the Kaggle EyePACS test set and 0.80 on Messidor-2 did not come close to the reported AUC of 0.99 in the original study. This may be caused by the use of a single grade per image, different data, or different not described hyper-parameter settings. This study shows the challenges of replicating deep learning, and the need for more replication studies to validate deep learning methods, especially for medical image analysis. Our source code and instructions are available at: https://github.com/mikevoets/jama16-retina-replication},
author = {M. Voets and Kajsa Møllersen and L. A. Bongo},
journal = {ArXiv},
volume = {abs/1803.04337},
pages = {null},
doi = {10.1371/journal.pone.0217541},
arxivid = {1803.04337},
}

@article{5cdfbb95a0ff42171b03493f5c59772b47ef3385,
title = {Automated Identification of Diabetic Retinopathy Using Deep Learning.},
year = {2017},
url = {https://www.semanticscholar.org/paper/5cdfbb95a0ff42171b03493f5c59772b47ef3385},
abstract = {S2 TL;DR: A fully data-driven artificial intelligence-based grading algorithm can be used to screen fundus photographs obtained from diabetic patients and to identify, with high reliability, which cases should be referred to an ophthalmologist for further evaluation and treatment.},
author = {Rishab Gargeya and T. Leng},
journal = {Ophthalmology},
volume = {124 7},
pages = {
          962-969
        },
doi = {10.1016/j.ophtha.2017.02.008},
pmid = {28359545},
}

@article{5c45a5d05ac564adb67811eeb9d41d6460c70135,
title = {Development and Validation of a Deep Learning Algorithm for Detection of Diabetic Retinopathy in Retinal Fundus Photographs.},
year = {2016},
url = {https://www.semanticscholar.org/paper/5c45a5d05ac564adb67811eeb9d41d6460c70135},
abstract = {Importance
Deep learning is a family of computational methods that allow an algorithm to program itself by learning from a large set of examples that demonstrate the desired behavior, removing the need to specify rules explicitly. Application of these methods to medical imaging requires further assessment and validation.


Objective
To apply deep learning to create an algorithm for automated detection of diabetic retinopathy and diabetic macular edema in retinal fundus photographs.


Design and Setting
A specific type of neural network optimized for image classification called a deep convolutional neural network was trained using a retrospective development data set of 128 175 retinal images, which were graded 3 to 7 times for diabetic retinopathy, diabetic macular edema, and image gradability by a panel of 54 US licensed ophthalmologists and ophthalmology senior residents between May and December 2015. The resultant algorithm was validated in January and February 2016 using 2 separate data sets, both graded by at least 7 US board-certified ophthalmologists with high intragrader consistency.


Exposure
Deep learning-trained algorithm.


Main Outcomes and Measures
The sensitivity and specificity of the algorithm for detecting referable diabetic retinopathy (RDR), defined as moderate and worse diabetic retinopathy, referable diabetic macular edema, or both, were generated based on the reference standard of the majority decision of the ophthalmologist panel. The algorithm was evaluated at 2 operating points selected from the development set, one selected for high specificity and another for high sensitivity.


Results
The EyePACS-1 data set consisted of 9963 images from 4997 patients (mean age, 54.4 years; 62.2% women; prevalence of RDR, 683/8878 fully gradable images [7.8%]); the Messidor-2 data set had 1748 images from 874 patients (mean age, 57.6 years; 42.6% women; prevalence of RDR, 254/1745 fully gradable images [14.6%]). For detecting RDR, the algorithm had an area under the receiver operating curve of 0.991 (95% CI, 0.988-0.993) for EyePACS-1 and 0.990 (95% CI, 0.986-0.995) for Messidor-2. Using the first operating cut point with high specificity, for EyePACS-1, the sensitivity was 90.3% (95% CI, 87.5%-92.7%) and the specificity was 98.1% (95% CI, 97.8%-98.5%). For Messidor-2, the sensitivity was 87.0% (95% CI, 81.1%-91.0%) and the specificity was 98.5% (95% CI, 97.7%-99.1%). Using a second operating point with high sensitivity in the development set, for EyePACS-1 the sensitivity was 97.5% and specificity was 93.4% and for Messidor-2 the sensitivity was 96.1% and specificity was 93.9%.


Conclusions and Relevance
In this evaluation of retinal fundus photographs from adults with diabetes, an algorithm based on deep machine learning had high sensitivity and specificity for detecting referable diabetic retinopathy. Further research is necessary to determine the feasibility of applying this algorithm in the clinical setting and to determine whether use of the algorithm could lead to improved care and outcomes compared with current ophthalmologic assessment.},
author = {Varun Gulshan and L. Peng and Marc Coram and Martin C. Stumpe and Derek J. Wu and Arunachalam Narayanaswamy and Subhashini Venugopalan and Kasumi Widner and T. Madams and Jorge A Cuadros and R. Kim and R. Raman and Philip Nelson and J. Mega and D. Webster},
journal = {JAMA},
volume = {316 22},
pages = {
          2402-2410
        },
doi = {10.1001/jama.2016.17216},
pmid = {27898976},
}

@article{8d00cff4b7b099cb6207c708a1ab9187a89f90dd,
title = {Convolutional Neural Networks for Diabetic Retinopathy},
year = {2016},
url = {https://www.semanticscholar.org/paper/8d00cff4b7b099cb6207c708a1ab9187a89f90dd},
abstract = {S2 TL;DR: A network with CNN architecture and data augmentation is developed which can identify the intricate features involved in the classification task such as micro-aneurysms, exudate and haemorrhages on the retina and consequently provide a diagnosis automatically and without user input.},
author = {H. Pratt and Frans Coenen and D. Broadbent and S. Harding and Yalin Zheng},
doi = {10.1016/j.procs.2016.07.014},
}

@article{9eecb9729ad4671467d8955483d379c46833a8d5,
title = {Development and Validation of a Deep Learning System to Detect Glaucomatous Optic Neuropathy Using Fundus Photographs.},
year = {2019},
url = {https://www.semanticscholar.org/paper/9eecb9729ad4671467d8955483d379c46833a8d5},
abstract = {Importance
A deep learning system (DLS) that could automatically detect glaucomatous optic neuropathy (GON) with high sensitivity and specificity could expedite screening for GON.


Objective
To establish a DLS for detection of GON using retinal fundus images and glaucoma diagnosis with convoluted neural networks (GD-CNN) that has the ability to be generalized across populations.


Design, Setting, and Participants
In this cross-sectional study, a DLS for the classification of GON was developed for automated classification of GON using retinal fundus images obtained from the Chinese Glaucoma Study Alliance, the Handan Eye Study, and online databases. The researchers selected 241 032 images were selected as the training dataset. The images were entered into the databases on June 9, 2009, obtained on July 11, 2018, and analyses were performed on December 15, 2018. The generalization of the DLS was tested in several validation datasets, which allowed assessment of the DLS in a clinical setting without exclusions, testing against variable image quality based on fundus photographs obtained from websites, evaluation in a population-based study that reflects a natural distribution of patients with glaucoma within the cohort and an additive dataset that has a diverse ethnic distribution. An online learning system was established to transfer the trained and validated DLS to generalize the results with fundus images from new sources. To better understand the DLS decision-making process, a prediction visualization test was performed that identified regions of the fundus images utilized by the DLS for diagnosis.


Exposures
Use of a deep learning system.


Main Outcomes and Measures
Area under the receiver operating characteristics curve (AUC), sensitivity and specificity for DLS with reference to professional graders.


Results
From a total of 274 413 fundus images initially obtained from CGSA, 269 601 images passed initial image quality review and were graded for GON. A total of 241 032 images (definite GON 29 865 [12.4%], probable GON 11 046 [4.6%], unlikely GON 200 121 [83%]) from 68 013 patients were selected using random sampling to train the GD-CNN model. Validation and evaluation of the GD-CNN model was assessed using the remaining 28 569 images from CGSA. The AUC of the GD-CNN model in primary local validation datasets was 0.996 (95% CI, 0.995-0.998), with sensitivity of 96.2% and specificity of 97.7%. The most common reason for both false-negative and false-positive grading by GD-CNN (51 of 119 [46.3%] and 191 of 588 [32.3%]) and manual grading (50 of 113 [44.2%] and 183 of 538 [34.0%]) was pathologic or high myopia.


Conclusions and Relevance
Application of GD-CNN to fundus images from different settings and varying image quality demonstrated a high sensitivity, specificity, and generalizability for detecting GON. These findings suggest that automated DLS could enhance current screening programs in a cost-effective and time-efficient manner.},
author = {MD HanruoLiu and PhDLiuLi and BEngI.MichaelWormstone and PhDChunyanQiao and PhDChunZhang and P. Md and PhDShuningLi and PhDHuaizhouWang and PhDDapengMou and PhDRuiqiPang and MD DiyaYang and PhDLindaM.Zangwill Md and PhDSasanMoghimi and MDHuiyuanHou and PhD ChristopherBowd and PhDLaiJiang and BEngYihanChen and MDManHu and PhDYongliXu and PhDHongKang and PhD XinJi and BEngRobertChang and PhDClementTham and PhDCarolCheung Md and PhDDanielShuWeiTing and Md and Phd and MD TienYinWong and PhDZulinWang and PhDRobertN.Weinreb and PhDMaiXu and PhDNingliWang and DrsH.Liu and H. Zhang and Wang},
journal = {JAMA ophthalmology},
volume = {null},
pages = {null},
doi = {10.1001/jamaophthalmol.2019.3501},
pmid = {31513266},
}

@article{0c711af7e6ea70eb876dddb2cf5ea32d975e53f4,
title = {Deep image mining for diabetic retinopathy screening},
year = {2016},
url = {https://www.semanticscholar.org/paper/0c711af7e6ea70eb876dddb2cf5ea32d975e53f4},
abstract = {S2 TL;DR: A ConvNet trained for image‐level classification can be used to detect lesions as well, and a generalization of the backpropagation method is proposed in order to train ConvNets that produce high‐quality heatmaps.},
author = {G. Quellec and K. Charrière and Yassine Boudi and B. Cochener and M. Lamard},
journal = {Medical Image Analysis},
volume = {39},
pages = {178–193},
doi = {10.1016/j.media.2017.04.012},
pmid = {28511066},
arxivid = {1610.07086},
}

@article{56011dcdf625649f112538e9d526040b81664efc,
title = {Performance of Deep Learning Architectures and Transfer Learning for Detecting Glaucomatous Optic Neuropathy in Fundus Photographs},
year = {2018},
url = {https://www.semanticscholar.org/paper/56011dcdf625649f112538e9d526040b81664efc},
abstract = {S2 TL;DR: The results suggest that deep learning-based assessment of fundus images could be useful in clinical decision support systems and in the automation of large-scale glaucoma detection and screening programs.},
author = {Mark A. Christopher and A. Belghith and C. Bowd and J. Proudfoot and M. Goldbaum and R. Weinreb and C. Girkin and J. Liebmann and L. Zangwill},
journal = {Scientific Reports},
volume = {8},
pages = {null},
doi = {10.1038/s41598-018-35044-9},
pmid = {30420630},
}

@article{23cd614b5ff50b99b9a6797bf9e20b9a1e37a346,
title = {Transforming Retinal Photographs to Entropy Images in Deep Learning to Improve Automated Detection for Diabetic Retinopathy},
year = {2018},
url = {https://www.semanticscholar.org/paper/23cd614b5ff50b99b9a6797bf9e20b9a1e37a346},
abstract = {Entropy images, representing the complexity of original fundus photographs, may strengthen the contrast between diabetic retinopathy (DR) lesions and unaffected areas. The aim of this study is to compare the detection performance for severe DR between original fundus photographs and entropy images by deep learning. A sample of 21,123 interpretable fundus photographs obtained from a publicly available data set was expanded to 33,000 images by rotating and flipping. All photographs were transformed into entropy images using block size 9 and downsized to a standard resolution of 100 × 100 pixels. The stages of DR are classified into 5 grades based on the International Clinical Diabetic Retinopathy Disease Severity Scale: Grade 0 (no DR), Grade 1 (mild nonproliferative DR), Grade 2 (moderate nonproliferative DR), Grade 3 (severe nonproliferative DR), and Grade 4 (proliferative DR). Of these 33,000 photographs, 30,000 images were randomly selected as the training set, and the remaining 3,000 images were used as the testing set. Both the original fundus photographs and the entropy images were used as the inputs of convolutional neural network (CNN), and the results of detecting referable DR (Grades 2–4) as the outputs from the two data sets were compared. The detection accuracy, sensitivity, and specificity of using the original fundus photographs data set were 81.80%, 68.36%, 89.87%, respectively, for the entropy images data set, and the figures significantly increased to 86.10%, 73.24%, and 93.81%, respectively (all p values <0.001). The entropy image quantifies the amount of information in the fundus photograph and efficiently accelerates the generating of feature maps in the CNN. The research results draw the conclusion that transformed entropy imaging of fundus photographs can increase the machinery detection accuracy, sensitivity, and specificity of referable DR for the deep learning-based system.},
author = {Gen-Min Lin and Mei-Juan Chen and C. Yeh and Yu-Yang Lin and Heng-Yu Kuo and Min-Hui Lin and Ming Chen and Shinfeng D. Lin and Ying Gao and A. Ran and C. Cheung},
journal = {Journal of Ophthalmology},
volume = {2018},
pages = {null},
doi = {10.1155/2018/2159702},
pmid = {30275989},
}

@article{59713f9e986cd730f48debecbf452dcac98b8b48,
title = {Using a Deep Learning System That Classifies Hypertensive Retinopathy Based on the Fundus Images of Patients of Wide Age},
year = {2021},
url = {https://www.semanticscholar.org/paper/59713f9e986cd730f48debecbf452dcac98b8b48},
abstract = {Received: 23 November 2020 Accepted: 2 February 2021 Range throughout Turkey in this paper, the author trained the continuous neural networks, and used a total of 4,000 fundus images, including images with different degrees of fundus disorders and images without disorders, so that CNN can detect whether the patient has hypertension and arteriosclerosis according to macular degeneration in the fundus images. In order to obtain more effective results from the deep learning structure using convolutional neural network, this paper prepared more data sets on the basis of Turkey, combined with the local data sets to educate the deep learning model, so as to integrate the data globally, which can help standardize the results and improve the accuracy. The system is used to diagnose retinal vascular degeneration, such as fundus vascular disease and macular edema disease. Based on this basic understanding, the research has been used for the detection and classification of hypertensive retinopathy that has similar causes. The author also points out the limitations of the system. Among them, the most important limitation is the need for long-term financial sustainability.},
author = {SüleymanBurçin Şüyun and Sakir Tasdemir and Serkan Biliş and A. Milea},
journal = {Traitement du Signal},
volume = {38},
pages = {207-213},
doi = {10.18280/TS.380122},
}

@article{b0b31784e73de88c0e164cb5cb15eecaac5a02c6,
title = {Automated diabetic retinopathy detection in smartphone-based fundus photography using artificial intelligence},
year = {2018},
url = {https://www.semanticscholar.org/paper/b0b31784e73de88c0e164cb5cb15eecaac5a02c6},
abstract = {S2 TL;DR: Automated AI analysis of FOP smartphone retinal imaging has very high sensitivity for detecting DR and STDR and thus can be an initial tool for mass retinal screening in people with diabetes.},
author = {R. Rajalakshmi and R. Subashini and R. Anjana and V. Mohan},
journal = {Eye},
volume = {32},
pages = {1138 - 1144},
doi = {10.1038/s41433-018-0064-9},
pmid = {29520050},
}

@article{a4ad11fe548e3bd371c66250c84cd1514419ea14,
title = {Automated analysis of retinal images for detection of referable diabetic retinopathy.},
year = {2013},
url = {https://www.semanticscholar.org/paper/a4ad11fe548e3bd371c66250c84cd1514419ea14},
abstract = {IMPORTANCE
The diagnostic accuracy of computer detection programs has been reported to be comparable to that of specialists and expert readers, but no computer detection programs have been validated in an independent cohort using an internationally recognized diabetic retinopathy (DR) standard.


OBJECTIVE
To determine the sensitivity and specificity of the Iowa Detection Program (IDP) to detect referable diabetic retinopathy (RDR).


DESIGN AND SETTING
In primary care DR clinics in France, from January 1, 2005, through December 31, 2010, patients were photographed consecutively, and retinal color images were graded for retinopathy severity according to the International Clinical Diabetic Retinopathy scale and macular edema by 3 masked independent retinal specialists and regraded with adjudication until consensus. The IDP analyzed the same images at a predetermined and fixed set point. We defined RDR as more than mild nonproliferative retinopathy and/or macular edema.


PARTICIPANTS
A total of 874 people with diabetes at risk for DR.


MAIN OUTCOME MEASURES
Sensitivity and specificity of the IDP to detect RDR, area under the receiver operating characteristic curve, sensitivity and specificity of the retinal specialists' readings, and mean interobserver difference (κ).


RESULTS
The RDR prevalence was 21.7% (95% CI, 19.0%-24.5%). The IDP sensitivity was 96.8% (95% CI, 94.4%-99.3%) and specificity was 59.4% (95% CI, 55.7%-63.0%), corresponding to 6 of 874 false-negative results (none met treatment criteria). The area under the receiver operating characteristic curve was 0.937 (95% CI, 0.916-0.959). Before adjudication and consensus, the sensitivity/specificity of the retinal specialists were 0.80/0.98, 0.71/1.00, and 0.91/0.95, and the mean intergrader κ was 0.822.


CONCLUSIONS
The IDP has high sensitivity and specificity to detect RDR. Computer analysis of retinal photographs for DR and automated detection of RDR can be implemented safely into the DR screening pipeline, potentially improving access to screening and health care productivity and reducing visual loss through early treatment.},
author = {M. Abràmoff and J. Folk and Dennis P. Han and Jonathan D. Walker and David F. Williams and S. Russell and P. Massin and B. Cochener and P. Gain and L. Tang and M. Lamard and D. Moga and G. Quellec and M. Niemeijer},
journal = {JAMA ophthalmology},
volume = {131 3},
pages = {
          351-7
        },
doi = {10.1001/jamaophthalmol.2013.1743},
pmid = {23494039},
}

@article{e1ec11a1cb3d9745fb18d3bf74247f95a6663d08,
title = {Dermatologist-level classification of skin cancer with deep neural networks},
year = {2017},
url = {https://www.semanticscholar.org/paper/e1ec11a1cb3d9745fb18d3bf74247f95a6663d08},
abstract = {S2 TL;DR: This work demonstrates an artificial intelligence capable of classifying skin cancer with a level of competence comparable to dermatologists, trained end-to-end from images directly, using only pixels and disease labels as inputs.},
author = {A. Esteva and Brett Kuprel and R. Novoa and J. Ko and S. Swetter and H. Blau and S. Thrun},
journal = {Nature},
volume = {542},
pages = {115-118},
doi = {10.1038/nature21056},
pmid = {28117445},
}

@article{364128bcce9836d60e685bb717b80f30e25092e0,
title = {Identifying Medical Diagnoses and Treatable Diseases by Image-Based Deep Learning},
year = {2018},
url = {https://www.semanticscholar.org/paper/364128bcce9836d60e685bb717b80f30e25092e0},
abstract = {S2 TL;DR: A diagnostic tool based on a deep-learning framework for the screening of patients with common treatable blinding retinal diseases, which demonstrates performance comparable to that of human experts in classifying age-related macular degeneration and diabetic macular edema.},
author = {Daniel S. Kermany and Daniel S. Kermany and M. Goldbaum and Wenjia Cai and C. Valentim and Huiying Liang and Sally L. Baxter and A. McKeown and Ge Yang and Xiaokang Wu and Fangbing Yan and J. Dong and Made K. Prasadha and Jacqueline Pei and Jacqueline Pei and M. Y. Ting and Jie Zhu and Christina M. Li and Sierra Hewett and Sierra Hewett and Jason Dong and Ian Ziyar and Alexander Shi and Runze Zhang and Lianghong Zheng and Rui Hou and W. Shi and Xin Fu and Xin Fu and Yaou Duan and V. N. Huu and V. N. Huu and Cindy Wen and Edward Zhang and Edward Zhang and Charlotte L. Zhang and Charlotte L. Zhang and Oulan Li and Oulan Li and Xiaobo Wang and M. Singer and Xiaodong Sun and Jie Xu and A. Tafreshi and M. Lewis and H. Xia and Kang Zhang},
journal = {Cell},
volume = {172},
pages = {1122-1131.e9},
doi = {10.1016/j.cell.2018.02.010},
pmid = {29474911},
}

@article{13e478175208b159d8c6fd34abc588fcbac204e3,
title = {Prediction of cardiovascular risk factors from retinal fundus photographs via deep learning},
year = {2017},
url = {https://www.semanticscholar.org/paper/e9d8481141d189e763889f44fb2626a23e2da9ce},
abstract = {S2 TL;DR: Deep learning predicts, from retinal images, cardiovascular risk factors not previously thought to be present or quantifiable in these images, not previously thought to be present or quantifiable in these images.},
author = {R. Poplin and A. Varadarajan and Katy Blumer and Yun Liu and M. McConnell and G. Corrado and L. Peng and D. Webster},
journal = {Nature Biomedical Engineering},
volume = {2},
pages = {158 - 164},
doi = {10.1038/s41551-018-0195-0},
pmid = {31015713},
arxivid = {1708.09843},
}

@article{1a305e806f3d9b966c302831073b70946d4231da,
title = {Improved Automated Detection of Diabetic Retinopathy on a Publicly Available Dataset Through Integration of Deep Learning.},
year = {2016},
url = {https://www.semanticscholar.org/paper/1a305e806f3d9b966c302831073b70946d4231da},
abstract = {Purpose
To compare performance of a deep-learning enhanced algorithm for automated detection of diabetic retinopathy (DR), to the previously published performance of that algorithm, the Iowa Detection Program (IDP)-without deep learning components-on the same publicly available set of fundus images and previously reported consensus reference standard set, by three US Board certified retinal specialists.


Methods
We used the previously reported consensus reference standard of referable DR (rDR), defined as International Clinical Classification of Diabetic Retinopathy moderate, severe nonproliferative (NPDR), proliferative DR, and/or macular edema (ME). Neither Messidor-2 images, nor the three retinal specialists setting the Messidor-2 reference standard were used for training IDx-DR version X2.1. Sensitivity, specificity, negative predictive value, area under the curve (AUC), and their confidence intervals (CIs) were calculated.


Results
Sensitivity was 96.8% (95% CI: 93.3%-98.8%), specificity was 87.0% (95% CI: 84.2%-89.4%), with 6/874 false negatives, resulting in a negative predictive value of 99.0% (95% CI: 97.8%-99.6%). No cases of severe NPDR, PDR, or ME were missed. The AUC was 0.980 (95% CI: 0.968-0.992). Sensitivity was not statistically different from published IDP sensitivity, which had a CI of 94.4% to 99.3%, but specificity was significantly better than the published IDP specificity CI of 55.7% to 63.0%.


Conclusions
A deep-learning enhanced algorithm for the automated detection of DR, achieves significantly better performance than a previously reported, otherwise essentially identical, algorithm that does not employ deep learning. Deep learning enhanced algorithms have the potential to improve the efficiency of DR screening, and thereby to prevent visual loss and blindness from this devastating disease.},
author = {M. Abràmoff and Y. Lou and A. Erginay and Warren Clarida and R. Amelon and J. Folk and M. Niemeijer},
journal = {Investigative ophthalmology & visual science},
volume = {57 13},
pages = {
          5200-5206
        },
doi = {10.1167/iovs.16-19964},
pmid = {27701631},
}

@article{18fa21735246fd1900152f36db073b3a67c2b945,
title = {A Deep Learning Algorithm for Prediction of Age-Related Eye Disease Study Severity Scale for Age-Related Macular Degeneration from Color Fundus Photography.},
year = {2018},
url = {https://www.semanticscholar.org/paper/18fa21735246fd1900152f36db073b3a67c2b945},
abstract = {S2 TL;DR: The authors' deep learning algoritm revealed a weighted κ outperforming human graders in the AREDS study and is suitable to classify AMD fundus images in other datasets using individuals >55 years of age.},
author = {F. Grassmann and Judith Mengelkamp and C. Brandl and Sebastian Harsch and M. Zimmermann and B. Linkohr and A. Peters and I. Heid and C. Palm and B. Weber},
journal = {Ophthalmology},
volume = {125 9},
pages = {
          1410-1420
        },
doi = {10.1016/j.ophtha.2018.02.037},
pmid = {29653860},
}

@article{14898d3fad28202dd4330165bf6ccef4f3b01d45,
title = {Who Said What: Modeling Individual Labelers Improves Classification},
year = {2017},
url = {https://www.semanticscholar.org/paper/14898d3fad28202dd4330165bf6ccef4f3b01d45},
abstract = {
 
 Data are often labeled by many different experts with each expert only labeling a small fraction of the data and each data point being labeled by several experts. This reduces the workload on individual experts and also gives a better estimate of the unobserved ground truth. When experts disagree, the standard approaches are to treat the majority opinion as the correct label or to model the correct label as a distribution. These approaches, however, do not make any use of potentially valuable information about which expert produced which label. To make use of this extra information, we propose modeling the experts individually and then learning averaging weights for combining them, possibly in sample-specific ways. This allows us to give more weight to more reliable experts and take advantage of the unique strengths of individual experts at classifying certain types of data. Here we show that our approach leads to improvements in computer-aided diagnosis of diabetic retinopathy. We also show that our method performs better than competing algorithms by Welinder and Perona (2010); Mnih and Hinton (2012). Our work offers an innovative approach for dealing with the myriad real-world settings that use expert opinions to define labels for training.
 
},
author = {M. Guan and Varun Gulshan and Andrew M. Dai and Geoffrey E. Hinton},
doi = {10.1609/aaai.v32i1.11756},
arxivid = {1703.08774},
}

@article{e35f243b2d2c60d4c3b03379d44901dc597e175d,
title = {Diagnostic accuracy of deep learning in medical imaging: a systematic review and meta-analysis},
year = {2021},
url = {https://www.semanticscholar.org/paper/e35f243b2d2c60d4c3b03379d44901dc597e175d},
abstract = {S2 TL;DR: There is an immediate need for the development of artificial intelligence-specific EQUATOR guidelines, particularly STARD, in order to provide guidance around key issues in this field.},
author = {R. Aggarwal and V. Sounderajah and G. Martin and D. Ting and A. Karthikesalingam and Dominic King and H. Ashrafian and A. Darzi},
journal = {NPJ Digital Medicine},
volume = {4},
pages = {null},
doi = {10.1038/s41746-021-00438-z},
pmid = {33828217},
}
